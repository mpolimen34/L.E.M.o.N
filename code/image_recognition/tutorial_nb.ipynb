{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = tf.ones([1,2,3])\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     tensor1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 2.5, 3, 4]\n",
    "y = [1, 4, 7, 9, 15]\n",
    "plt.plot(x, y, 'ro')\n",
    "plt.axis([0, 6, 0, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'ro')\n",
    "plt.axis([0, 6, 0, 20])\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.sex.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain['class'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "  def input_function():  # inner function, this will be returned\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(1000)  # randomize order of data\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
    "    return ds  # return a batch of the dataset\n",
    "  return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "# We create a linear estimtor by passing the feature columns we created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est.train(train_input_fn)  # train\n",
    "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n",
    "\n",
    "clear_output()  # clears consoke output\n",
    "print(result['accuracy'])  # the result variable is simply a dict of stats about our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "\n",
    "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Lets define some constants to help us later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head() # the species column is now gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape  # we have 120 entires with 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "  valid = True\n",
    "  while valid: \n",
    "    val = input(feature + \": \")\n",
    "    if not val.isdigit(): valid = False\n",
    "\n",
    "  predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some example input and expected classes you can try above\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist  # load dataset\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  # split into tetsing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0,23,23]  # let's have a look at one pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[:10]  # let's have a look at the first 10 training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[1])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_labels))\n",
    "print(type(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # input layer (1)\n",
    "    keras.layers.Dense(128, activation='relu'),  # hidden layer (2)\n",
    "    keras.layers.Dense(10, activation='softmax') # output layer (3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)  # we pass the data, labels and epochs and watch the magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1) \n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR = 'white'\n",
    "plt.rcParams['text.color'] = COLOR\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "\n",
    "def predict(model, image, correct_label):\n",
    "  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "  prediction = model.predict(np.array([image]))\n",
    "  predicted_class = class_names[np.argmax(prediction)]\n",
    "\n",
    "  show_image(image, class_names[correct_label], predicted_class)\n",
    "\n",
    "\n",
    "def show_image(img, label, guess):\n",
    "  plt.figure()\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  plt.title(\"Excpected: \" + label)\n",
    "  plt.xlabel(\"Guess: \" + guess)\n",
    "  plt.colorbar()\n",
    "  plt.grid(False)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def get_number():\n",
    "  while True:\n",
    "    num = input(\"Pick a number: \")\n",
    "    if num.isdigit():\n",
    "      num = int(num)\n",
    "      if 0 <= num <= 1000:\n",
    "        return int(num)\n",
    "    else:\n",
    "      print(\"Try again...\")\n",
    "\n",
    "num = get_number()\n",
    "image = test_images[num]\n",
    "label = test_labels[num]\n",
    "predict(model, image, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 102s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#  LOAD AND SPLIT DATASET\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at a one image\n",
    "IMG_INDEX = 7  # change this to look at other images\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # let's have a look at our model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.5548 - accuracy: 0.4320 - val_loss: 1.2556 - val_accuracy: 0.5494\n",
      "Epoch 2/4\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.1906 - accuracy: 0.5762 - val_loss: 1.1477 - val_accuracy: 0.5985\n",
      "Epoch 3/4\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.0250 - accuracy: 0.6392 - val_loss: 0.9808 - val_accuracy: 0.6574\n",
      "Epoch 4/4\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 0.9175 - accuracy: 0.6761 - val_loss: 0.9382 - val_accuracy: 0.6686\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=4, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.9382 - accuracy: 0.6686\n",
      "0.6686000227928162\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
